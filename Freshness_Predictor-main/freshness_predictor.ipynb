{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Desktop\\fruits\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\Desktop\\fruits\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_11964\\2234620468.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_vgg16.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define the ModelVGG16 class\n",
    "class ModelVGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = 0.7\n",
    "        \n",
    "        self.base = models.vgg16(pretrained=True)\n",
    "        \n",
    "        # Freeze all layers except the last 15\n",
    "        for param in list(self.base.parameters())[:-15]:\n",
    "            param.requires_grad = False\n",
    "                    \n",
    "        self.base.classifier = nn.Sequential()  # Clear classifier\n",
    "        self.base.fc = nn.Sequential()  # Remove fc layers\n",
    "            \n",
    "        # Custom blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 256),  # Adjust input size based on VGG16 output\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 9)  # Assuming 9 classes of fruits\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 2)  # Fresh or Stale (binary classification)\n",
    "        )\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer1 = optim.Adam([{'params': self.base.parameters(), 'lr': 1e-5},\n",
    "                                      {'params': self.block1.parameters(), 'lr': 3e-4}])\n",
    "        self.optimizer2 = optim.Adam(self.block2.parameters(), lr=3e-4)\n",
    "        self.optimizer3 = optim.Adam(self.block3.parameters(), lr=3e-4)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fxn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Accuracy metrics\n",
    "        self.fruit_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=9)\n",
    "        self.fresh_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base.features(x)  # Use VGG16's convolutional layers\n",
    "        x = torch.flatten(x, 1)    # Flatten the output\n",
    "        x = self.block1(x)         # Pass through custom block1\n",
    "        y1, y2 = self.block2(x), self.block3(x)  # Get predictions from block2 and block3\n",
    "        return y1, y2\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model_vgg16 = ModelVGG16().to(device)\n",
    "\n",
    "# **Load your pre-trained model**\n",
    "# Replace 'model.pth' with the correct path to your downloaded model file\n",
    "model_path = \"model.pth\"  # Ensure 'model.pth' is in the same directory or provide the full path\n",
    "try:\n",
    "    # If you saved only the state_dict\n",
    "    model_vgg16.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model: {e}\")\n",
    "\n",
    "model_vgg16.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# **Update the class names to match your model's output**\n",
    "# Assuming your model's block2 outputs 9 fruit classes\n",
    "class_names = [\n",
    "    'apple', 'banana', 'orange', 'strawberry', 'tomato',\n",
    "    'grape', 'pineapple', 'mango', 'blueberry'  # Add up to 9 classes\n",
    "]\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Convert RGBA to RGB if necessary\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    # Define the transformations (same as before)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((244, 244)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Apply the transformation\n",
    "    img_t = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img_t\n",
    "\n",
    "\n",
    "# Function to run the prediction\n",
    "def predict_freshness(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_vgg16(image)\n",
    "        # Assuming the model has two outputs for fruit type and freshness\n",
    "        fruit_pred = torch.argmax(outputs[0], axis=1).cpu().numpy()[0]\n",
    "        fresh_pred = torch.argmax(outputs[1], axis=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Map the predictions to labels\n",
    "    fruit_label = class_names[fruit_pred]  # Ensure class_names has 9 classes\n",
    "    freshness_label = 'Fresh' if fresh_pred == 0 else 'Stale'\n",
    "    \n",
    "    return fruit_label, freshness_label\n",
    "\n",
    "# Function to open the file dialog and get the image\n",
    "def open_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        try:\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((244, 244))  # Adjust to match display size\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "            panel.config(image=img_tk)\n",
    "            panel.image = img_tk\n",
    "\n",
    "            # Run prediction\n",
    "            fruit_label, freshness_label = predict_freshness(file_path)\n",
    "            result_label.config(text=f\"Prediction: {fruit_label}, {freshness_label}\")\n",
    "        except Exception as e:\n",
    "            result_label.config(text=f\"Error processing image: {e}\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Fruit Freshness Predictor\")\n",
    "\n",
    "# Add a button to load the image\n",
    "btn = tk.Button(root, text=\"Load Image\", command=open_image)\n",
    "btn.pack(pady=10)\n",
    "\n",
    "# Add a label to display the prediction result\n",
    "result_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Add a panel to display the selected image\n",
    "panel = tk.Label(root)\n",
    "panel.pack(pady=10)\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
